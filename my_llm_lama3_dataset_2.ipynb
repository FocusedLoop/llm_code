{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2185429697.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install matplotlib\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch accelerate peft\n",
    "pip install kagglehub\n",
    "pip install matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshua\\Desktop\\python_ai\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os, json, random\n",
    "from textwrap import dedent\n",
    "from typing import Dict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, AutoTokenizer, BitsAndBytesConfig, pipeline\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joshua\\Desktop\\python_ai\\.venv\\Lib\\site-packages\\accelerate\\utils\\modeling.py:841: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  _ = torch.tensor([0], device=i)\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.60s/it]\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size: 128261\n",
      "Model embedding size: 128261\n",
      "Special tokens:\n",
      "  BOS token: <s>\n",
      "  EOS token: </s>\n",
      "  PAD token: </s>\n",
      "  Additional special tokens: ['<EQ>', '<EXPL>']\n"
     ]
    }
   ],
   "source": [
    "model_id = r\"C:\\Users\\Joshua\\Desktop\\python_ai\\llm_code\\llama31\\Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# Loading model\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ") # INSPECT MORE\n",
    "\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Tokenizer\n",
    "special_tokens_dict = {\n",
    "    \"bos_token\": \"<s>\",\n",
    "    \"eos_token\": \"</s>\",\n",
    "    \"pad_token\": \"<pad>\",\n",
    "    \"additional_special_tokens\": [\"<EQ>\", \"<EXPL>\"]\n",
    "}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "add_special_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "if add_special_tokens > 0:\n",
    "    llm_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Debug\n",
    "print(\"Tokenizer vocabulary size:\", len(tokenizer))\n",
    "print(\"Model embedding size:\", llm_model.get_input_embeddings().weight.size(0))\n",
    "print(\"Special tokens:\")\n",
    "print(\"  BOS token:\", tokenizer.bos_token)\n",
    "print(\"  EOS token:\", tokenizer.eos_token)\n",
    "print(\"  PAD token:\", tokenizer.pad_token)\n",
    "print(\"  Additional special tokens:\", tokenizer.additional_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To produce a build under $250.77\n",
      "\n",
      "1. **CPU**: Intel Core i5-10600KF 4.1 GHz 6-Core Processor - $84.22 USD\n",
      "2. **Motherboard**: Asus PRIME H410M-E Micro ATX LGA1200 Motherboard - $0.00 USD\n",
      "3. **Memory**: Corsair Vengeance LPX 16 GB (2 x 8 GB) DDR4-3200 CL16 Memory - $21.82 USD\n",
      "4. **Storage**: Toshiba DT01ACA200 2 TB 3.5\" 7200 RPM Internal Hard Drive - $0.00 USD\n",
      "5. **Storage**: Western Digital SN530 512 GB M.2-2280 PCIe 3.0 X4 NVME Solid State Drive - $21.82 USD\n",
      "6. **Video Card**: Asus Phoenix OC GeForce GTX 1660 SUPER 6 GB Video Card - $72.73 USD\n",
      "7. **Case**: KOLINK OBSERVATORY LITE MESH RGB ATX Mid Tower Case - $21.82 USD\n",
      "8. **Custom**: ZALMAN's CNPS9X Optima w/White LED Fan - $13.96 USD\n",
      "9. **Custom**: LogiLink PC0057 PCI Expres Card 4x USB3.0 - $14.40 USD\n",
      "10. **Custom**: Energon EP​​S-750W IT​E​M NO.: 8​88​82021 -                                     $0.00 USD\n",
      "                                \n",
      "\n",
      "**Total Cost:**: $250.77\n"
     ]
    }
   ],
   "source": [
    "dataset_path = r\"C:\\Users\\Joshua\\Desktop\\python_ai\\llm_code\\datasets\\pc_build_parts.json\"\n",
    "\n",
    "with open(dataset_path, 'r') as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "\n",
    "budget_template = \"Build me a PC around ${budget}.\"\n",
    "\n",
    "def format_parts(parts, float_cost, total):\n",
    "    result = f\"To produce a build under ${float_cost}\\n\\n\"\n",
    "    for i, part in enumerate(parts, start=1):\n",
    "        result += f\"{i}. **{part['Type']}**: {part['Name']} - {part['Price']}\\n\"\n",
    "    result += f\"\\n**Total Cost:**: ${total}\"\n",
    "    return result\n",
    "\n",
    "def round_to_nearest_100(value):\n",
    "    return round(value / 100) * 100\n",
    "\n",
    "rows = []\n",
    "for build in dataset:\n",
    "    description = \" \".join(build[\"Description\"])\n",
    "    parts = build[\"Part List\"][\"Parts\"]\n",
    "    total_cost = build[\"Part List\"][\"Total\"]\n",
    "    clean_cost = re.sub(r'[^0-9.]', '', total_cost)\n",
    "    float_cost = float(clean_cost)\n",
    "\n",
    "    rows.append({\n",
    "        \"question\": budget_template.format(budget=round_to_nearest_100(float_cost)),\n",
    "        \"context\": f\"{description}.\",\n",
    "        \"answer\": f\"{format_parts(parts, float_cost, clean_cost)}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "formatted_output = format_parts(parts, float_cost, clean_cost)\n",
    "print(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Build me a PC around $1300.</td>\n",
       "      <td>My Sons 1st Build.. used for school and some g...</td>\n",
       "      <td>To produce a build under $1284.46\\n\\n1. **CPU*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Build me a PC around $2500.</td>\n",
       "      <td>My first gaming pc in 8 years and first ever s...</td>\n",
       "      <td>To produce a build under $2520.0\\n\\n1. **CPU**...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Build me a PC around $4200.</td>\n",
       "      <td>Built the quietest gaming PC with an AMD Ryzen...</td>\n",
       "      <td>To produce a build under $4160.52\\n\\n1. **CPU*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Build me a PC around $600.</td>\n",
       "      <td>This is the product of some parts swaps for a ...</td>\n",
       "      <td>To produce a build under $571.96\\n\\n1. **CPU**...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Build me a PC around $4900.</td>\n",
       "      <td>Decided to upgrade form the 13900k to 14900kf....</td>\n",
       "      <td>To produce a build under $4949.51\\n\\n1. **CPU*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119315</th>\n",
       "      <td>Build me a PC around $6200.</td>\n",
       "      <td>Gaming..</td>\n",
       "      <td>To produce a build under $6241.34\\n\\n1. **CPU*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119316</th>\n",
       "      <td>Build me a PC around $3700.</td>\n",
       "      <td>cat videos at 8k WHO Aside from cat videos, th...</td>\n",
       "      <td>To produce a build under $3714.62\\n\\n1. **CPU*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119317</th>\n",
       "      <td>Build me a PC around $200.</td>\n",
       "      <td>After 4 years with the Ryzen 5 2600 and RX 570...</td>\n",
       "      <td>To produce a build under $187.77\\n\\n1. **CPU**...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119318</th>\n",
       "      <td>Build me a PC around $4100.</td>\n",
       "      <td>Built a PC for my gf and she made it her own. ...</td>\n",
       "      <td>To produce a build under $4102.53\\n\\n1. **CPU*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119319</th>\n",
       "      <td>Build me a PC around $300.</td>\n",
       "      <td>Leftovers from previous upgrades. The case was...</td>\n",
       "      <td>To produce a build under $250.77\\n\\n1. **CPU**...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119320 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           question  \\\n",
       "0       Build me a PC around $1300.   \n",
       "1       Build me a PC around $2500.   \n",
       "2       Build me a PC around $4200.   \n",
       "3        Build me a PC around $600.   \n",
       "4       Build me a PC around $4900.   \n",
       "...                             ...   \n",
       "119315  Build me a PC around $6200.   \n",
       "119316  Build me a PC around $3700.   \n",
       "119317   Build me a PC around $200.   \n",
       "119318  Build me a PC around $4100.   \n",
       "119319   Build me a PC around $300.   \n",
       "\n",
       "                                                  context  \\\n",
       "0       My Sons 1st Build.. used for school and some g...   \n",
       "1       My first gaming pc in 8 years and first ever s...   \n",
       "2       Built the quietest gaming PC with an AMD Ryzen...   \n",
       "3       This is the product of some parts swaps for a ...   \n",
       "4       Decided to upgrade form the 13900k to 14900kf....   \n",
       "...                                                   ...   \n",
       "119315                                           Gaming..   \n",
       "119316  cat videos at 8k WHO Aside from cat videos, th...   \n",
       "119317  After 4 years with the Ryzen 5 2600 and RX 570...   \n",
       "119318  Built a PC for my gf and she made it her own. ...   \n",
       "119319  Leftovers from previous upgrades. The case was...   \n",
       "\n",
       "                                                   answer  \n",
       "0       To produce a build under $1284.46\\n\\n1. **CPU*...  \n",
       "1       To produce a build under $2520.0\\n\\n1. **CPU**...  \n",
       "2       To produce a build under $4160.52\\n\\n1. **CPU*...  \n",
       "3       To produce a build under $571.96\\n\\n1. **CPU**...  \n",
       "4       To produce a build under $4949.51\\n\\n1. **CPU*...  \n",
       "...                                                   ...  \n",
       "119315  To produce a build under $6241.34\\n\\n1. **CPU*...  \n",
       "119316  To produce a build under $3714.62\\n\\n1. **CPU*...  \n",
       "119317  To produce a build under $187.77\\n\\n1. **CPU**...  \n",
       "119318  To produce a build under $4102.53\\n\\n1. **CPU*...  \n",
       "119319  To produce a build under $250.77\\n\\n1. **CPU**...  \n",
       "\n",
       "[119320 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().value_counts()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(row: dict):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    {row[\"question\"]}\n",
    "\n",
    "    Information:\n",
    "\n",
    "    ```\n",
    "    {row[\"context\"]}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\": \"Use only the information to answer the question\",\n",
    "        },\n",
    "        {\"role\":\"user\", \"content\": prompt},\n",
    "        {\"role\":\"assistant\", \"content\": row[\"answer\"]},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.apply(format_dataset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(row: Dict) -> int:\n",
    "    return len(\n",
    "        tokenizer(\n",
    "            row[\"text\"],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False,\n",
    "        )[\"input_ids\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"token_count\"] = df.apply(count_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.token_count, weights=np.ones(len(df.token_count)) / len(df.token_count))\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118465, 119320, 0.9939406637613141)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tell us the length\n",
    "len(df[df.token_count < 2000]), len(df), len(df[df.token_count < 2100]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.token_count < 2100]\n",
    "df = df.sample(11000)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 8800\n",
      "Validation dataset size: 1760\n",
      "Test dataset size: 440\n"
     ]
    }
   ],
   "source": [
    "train, temp = train_test_split(df, test_size=0.2)\n",
    "val, test = train_test_split(temp, test_size=0.2)\n",
    "\n",
    "print(f\"Train dataset size: {len(train)}\")\n",
    "print(f\"Validation dataset size: {len(val)}\")\n",
    "print(f\"Test dataset size: {len(test)}\")\n",
    "\n",
    "train.sample(n=8000).to_json(\"split_sets/train.json\", orient=\"records\", lines=True)\n",
    "val.sample(n=1500).to_json(\"split_sets/val.json\", orient=\"records\", lines=True)\n",
    "test.sample(n=400).to_json(\"split_sets/test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           question  \\\n",
      "118530  Build me a PC around $2600.   \n",
      "101161  Build me a PC around $3000.   \n",
      "107552  Build me a PC around $1300.   \n",
      "18825   Build me a PC around $1400.   \n",
      "81276   Build me a PC around $1400.   \n",
      "\n",
      "                                                  context  \\\n",
      "118530  Upgraded my last build with NZXT Kraken Elite ...   \n",
      "101161  First time building a PC from scratch. I decid...   \n",
      "107552  mainly gaming orientated with light useage of ...   \n",
      "18825   1k+ frames for modded minecraft so no complain...   \n",
      "81276   Built this for a friend's sons Xmas gift. Have...   \n",
      "\n",
      "                                                   answer  \\\n",
      "118530  To produce a build under $2613.65\\n\\n1. **CPU*...   \n",
      "101161  To produce a build under $2999.62\\n\\n1. **CPU*...   \n",
      "107552  To produce a build under $1250.39\\n\\n1. **CPU*...   \n",
      "18825   To produce a build under $1421.66\\n\\n1. **CPU*...   \n",
      "81276   To produce a build under $1399.77\\n\\n1. **CPU*...   \n",
      "\n",
      "                                                     text  token_count  \n",
      "118530  <s><|start_header_id|>system<|end_header_id|>\\...          784  \n",
      "101161  <s><|start_header_id|>system<|end_header_id|>\\...          757  \n",
      "107552  <s><|start_header_id|>system<|end_header_id|>\\...          332  \n",
      "18825   <s><|start_header_id|>system<|end_header_id|>\\...          451  \n",
      "81276   <s><|start_header_id|>system<|end_header_id|>\\...          608  \n"
     ]
    }
   ],
   "source": [
    "# Finetune Below\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 8000 examples [00:00, 90911.49 examples/s]\n",
      "Generating validation split: 1500 examples [00:00, 124994.16 examples/s]\n",
      "Generating test split: 400 examples [00:00, 50018.53 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Build me a PC around $2800.\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Based PC for gaming and such..\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "To produce a build under $2829.55\n",
      "\n",
      "1. **CPU**: Intel Core i7-13700K 3.4 GHz 16-Core Processor - $301.69 USD\n",
      "2. **Thermal Compound**: Arctic Silver 5 High-Density Polysynthetic Silver 12 g Thermal Paste - $26.00\n",
      "3. **Motherboard**: Asus ROG STRIX Z690-E GAMING WIFI ATX LGA1700 Motherboard - $180.36 USD\n",
      "4. **Memory**: Corsair Vengeance RGB 32 GB (2 x 16 GB) DDR5-6200 CL36 Memory - $209.00\n",
      "5. **Storage**: Samsung 850 Evo 500 GB 2.5\" Solid State Drive - None\n",
      "6. **Storage**: Samsung 860 QVO 1 TB 2.5\" Solid State Drive - $183.59\n",
      "7. **Storage**: Samsung 970 Evo Plus 1 TB M.2-2280 PCIe 3.0 X4 NVME Solid State Drive - $99.00\n",
      "8. **Storage**: Samsung 970 Evo Plus 2 TB M.2-2280 PCIe 3.0 X4 NVME Solid State Drive - $288.00\n",
      "9. **Storage**: Crucial BX500 1 TB 2.5\" Solid State Drive - $85.00\n",
      "10. **Storage**: Crucial BX500 1 TB 2.5\" Solid State Drive - $85.00\n",
      "11. **Storage**: Western Digital Black SN750 Rev2 500 GB M.2-2280 PCIe 3.0 X4 NVME Solid State Drive - None\n",
      "12. **Video Card**: Asus DUAL OC GeForce RTX 4060 Ti 8 GB Video Card - $770.00\n",
      "13. **Case**: Thermaltake Core P3 ATX Mid Tower Case - $334.88\n",
      "14. **Power Supply**: Corsair RM850 850 W 80+ Gold Certified Fully Modular ATX Power Supply - $199.00\n",
      "15. **Operating System**: Microsoft Windows 11 Pro OEM - DVD 64-bit - $229.00\n",
      "16. **Case Fan**: Corsair iCUE ML120 RGB ELITE Premium 58.1 CFM 120 mm Fans 3-Pack - $160.54\n",
      "17. **Case Fan**: Corsair iCUE ML120 RGB ELITE Premium 58.1 CFM 120 mm Fans 3-Pack - $160.54\n",
      "18. **Monitor**: Asus VH236H 23.0\" 1920 x 1080 Monitor - None\n",
      "19. **Monitor**: Acer Nitro KG251Q Z 24.5\" 1920 x 1080 250 Hz Monitor - None\n",
      "20. **Keyboard**: Ducky ONE 3 RGB Wired Gaming Keyboard - None\n",
      "21. **Mouse**: Logitech G502 X Plus Wired/Wired/Wireless Optical Mouse - None\n",
      "22. **Headphones**: Logitech G733  Headset - None\n",
      "23. **Custom**: 360mm Radiator, Copper CPU Water Cooling Heat Exchanger with 1/4 inch Thread, 12 Tubes, and Screw Kit, Universal Computer Heat Sink, White - None\n",
      "24. **Custom**: EKWB EK-Quantum Velocity 2 CPU Water Block D-RGB - 1700, Nickel/Satin Titanium - None\n",
      "25. **Custom**: Thermaltake Pacific Core P5 DP-D5 Plus Distro-Plate with Pump Combo CL-W264-PL00SW-A - None\n",
      "\n",
      "**Total Cost:**: $2829.55<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\": \"split_sets/train.json\", \"validation\": \"split_sets/val.json\", \"test\": \"split_sets/test.json\"},\n",
    ")\n",
    "print(dataset[\"train\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for taking in inputs\n",
    "# del pipeline\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=llm_model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    #device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_prompt(data_row):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    {data_row[\"question\"]}\n",
    "\n",
    "    Information:\n",
    "\n",
    "    ```\n",
    "    {data_row[\"context\"]}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\": \"Use only the information to answer the question\",\n",
    "        },\n",
    "        {\"role\":\"user\", \"content\": prompt},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "Use only the information to answer the question<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Build me a PC around $3000.\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "From HotPink to Black Out! Featuring Carbon fibre suspension support struts, custom mounting hardware for all the radiators and Bitspower's new Stealth Waterblock in collaboration with Modding Cafe. The full build took close to 1.5 months and as usualy i'd like to thank all the support from our sponsors Asrock, Antec, Kingston Technology, Bitspower, Monster studio, Mayhems Solutions and RCPC. This build combo is abit of a monster, running a 4090 Founders Edition Graphics Card, 13700k and 8000mt/s CL36 DDR5 Memory. It was also a great honour yesterday to showcase the build with Antec at the Target Open Day trade show to represent them on their stand.  Thank you!.\n",
      "```<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = dataset[\"test\"][0]\n",
    "prompt = create_test_prompt(row)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "answer:     To produce a build under $2954.44\n",
      "\n",
      "1. **CPU**: Intel Core i7-13700K 3.4 GHz 16-Core Processor - $529.00\n",
      "2. **Motherboard**: ASRock Z790I Lightning WiFi Mini ITX LGA1700 Motherboard - $471.08\n",
      "3. **Memory**: Kingston Fury Renegade RGB 48 GB (2 x 24 GB) DDR5-8000 CL36 Memory - $569.00\n",
      "4. **Storage**: Samsung 870 QVO 2 TB 2.5\" Solid State Drive - $350.36\n",
      "5. **Storage**: Samsung 870 QVO 2 TB 2.5\" Solid State Drive - $350.36\n",
      "6. **Storage**: Kingston Fury Renegade 1 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive - $149.00\n",
      "7. **Storage**: Crucial P5 Plus W/Heatsink 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive - $306.64\n",
      "8. **Video Card**: NVIDIA Founders Edition GeForce RTX 4090 24 GB Video Card - None\n",
      "9. **Case**: Monster St​udio A45 -                                     $250.00 USD\n",
      "                                \n",
      "10. **Power Supply**: Antec SF850X 850 W 80+ Gold Certified Fully Modular SFX Power Supply - $180.00 USD\n",
      "11. **Operating System**: Microsoft Windows 11 Pro OEM - DVD 64-bit - $229.00\n",
      "12. **Monitor**: Dell Alienware AW3423DWF 34.2\" 3440 x 1440 165 Hz Curved Monitor - None\n",
      "\n",
      "**Total Cost:**: $2954.44\n",
      "prediction: Based on the provided information, I'll attempt to build a PC around $3000. However, please note that the original build mentioned is a high-end system with a 4090 Founders Edition Graphics Card, 13700k CPU, and 8000mt/s CL36 DDR5 Memory, which is likely above the $3000 budget.\n",
      "\n",
      "To build a PC around $3000, I'll make some compromises on the components. Here's a suggested build:\n",
      "\n",
      "**CPU:** AMD Ryzen 9 5900X - $699\n",
      "**Motherboard:** ASRock X570M Steel Legend Micro ATX - $129\n",
      "**GPU:** NVIDIA GeForce RTX 3070 - $599\n",
      "**RAM:** Corsair Vengeance LPX 16GB (2x8GB) DDR4 3200MHz - $69\n",
      "**Storage:** Samsung 970 EVO Plus 1TB M.2 NVMe SSD - $179\n",
      "**Case:** Fractal Design Meshify C ATX Mid Tower Case - $59\n",
      "**Power Supply:** EVGA 650 GS, 80+ Gold 650W - $109\n",
      "**Cooling:** Noctua NH-U14S TR4-SP3 - $39\n",
      "**Operating System:** Windows 11 Home - $139\n",
      "\n",
      "Total Cost: $2822\n",
      "\n",
      "This build should provide a good balance of performance and features while staying within the $3000 budget. However, please note that prices may vary depending on the region and availability.\n",
      "\n",
      "If you'd like to make any adjustments or have specific preferences (e.g., CPU, GPU, or case), feel free to let me know!\n",
      "\n",
      "CPU times: total: 30.2 s\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = pipeline(\n",
    "    prompt, \n",
    "    max_new_tokens=2000,\n",
    "    length_penalty=1,\n",
    "    num_beams=5,\n",
    "    temperature=0.3,\n",
    "    top_p=0.8,\n",
    "    repetition_penalty=1,\n",
    "    )\n",
    "\n",
    "responce = f\"\"\"\n",
    "answer:     {row[\"answer\"]}\n",
    "prediction: {outputs[0][\"generated_text\"]}\n",
    "\"\"\"\n",
    "print(responce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForCompletionOnlyLM(response_template=\"<|end_header_id|>\", tokenizer=tokenizer)\n",
    "\n",
    "examples = [dataset[\"train\"][0][\"text\"]]\n",
    "endcodings = [tokenizer(e) for e in examples]\n",
    "\n",
    "dataloader = DataLoader(endcodings, collate_fn=collator, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "            271,  10267,    400,     88,    284,   1144,    848,     62,     17,\n",
       "            220,    679,     23,   2475,   5112,    555,    279,   2349,    315,\n",
       "           2385,  15150,     11,    369,    904,    400,     65,   4884,   1144,\n",
       "          27148,    848,  15511,     17,     61,     65,     92,    220,    679,\n",
       "             23,    284,   1144,  38118,  36802,    848,     62,     17,    220,\n",
       "            679,     23,  15523,     59,    848,     62,     17,    220,     17,\n",
       "             61,     65,     92,    284,   1144,  38118,  36802,    848,     62,\n",
       "             17,    220,    679,     23,  15523,     65,     92,   7255,     60,\n",
       "          45600,     11,  59060,    848,     62,     19,    220,    679,     23,\n",
       "            284,   1144,  38118,  36802,    848,     62,     17,    220,    679,\n",
       "             23,  15523,     17,     92,    284,   1144,  38118,    379,     17,\n",
       "           4884,  59060,    848,     62,     23,    220,    679,     23,    284,\n",
       "           1144,  38118,  36802,    848,     62,     17,    220,    679,     23,\n",
       "          15523,     18,     92,    284,   1144,  38118,    379,     18,   4884,\n",
       "            323,  59060,    848,  15511,   1227,     92,    220,    679,     23,\n",
       "            284,   1144,  38118,  36802,    848,     62,     17,    220,    679,\n",
       "             23,  15523,     21,     92,    284,   1144,  38118,    379,     21,\n",
       "           2475,  14636,     11,    279,   2163,  25417,   3185,   9221,   1144,\n",
       "             58,     88,    489,   1144,  38118,    379,     17,    489,   1144,\n",
       "          38118,    379,     18,    489,   1144,  38118,    379,     21,    284,\n",
       "           1144,   2414,      7,     16,  42815,  38118,    717,  42815,  38118,\n",
       "           1032,  42815,  38118,    845,     59,   1315,  84447,    284,    220,\n",
       "             17,     88,   7255,     60,  51197,    400,     65,  35533,     83,\n",
       "          38118,    717,   4884,    584,   1518,    430,   1144,  27148,    848,\n",
       "          15511,     17,  48922,     16,     14,     17,   3500,    220,    679,\n",
       "             23,    284,   1144,  38118,  36802,    848,     62,     17,    220,\n",
       "            679,     23,  15523,     16,     14,     17,     92,    284,    220,\n",
       "             17,     88,  27362,     60,    708,    279,   2163,  25417,   3185,\n",
       "          17239,  59060,    848,  15511,     17,  48922,     16,     14,     17,\n",
       "           3500,    220,    679,     23,   4884,    477,  59060,    848,  15511,\n",
       "             59,  27986,     17,     92,    220,    679,     23,   2475,  14636,\n",
       "             11,    400,     87,    284,   1144,  80175,  36802,  27986,     17,\n",
       "             92,   2475, 128009]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128261, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128261, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chosing layers to apply LoRA to\n",
    "llm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 83,886,080 || all params: 8,114,188,288 || trainable%: 1.0338\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type = \"CAUSAL_LM\", \n",
    "    r = 32, #64\n",
    "    lora_alpha = 16, #16\n",
    "    lora_dropout = 0.05, #0.1\n",
    "    bias = \"none\",\n",
    "    target_modules=[\n",
    "        \"self_attn.q_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"self_attn.o_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"mlp.down_proj\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "llm_model = prepare_model_for_kbit_training(llm_model)\n",
    "llm_model = get_peft_model(llm_model, peft_config)\n",
    "llm_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINETUNE WITH DIFFERENT DATA!!!!\n",
    "# MOVE WHERE YOU LOAD THE MODEL TO BELOW YOUR PIPELINE SO PLAY WITH MODEL CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=0XPZlR3_GgI\n",
    "# 21:45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./test_trainer\",\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# Fine tunning\n",
    "# Optimize training\n",
    "peft_config = LoraConfig(\n",
    "    task_type = \"CAUSAL_LM\", \n",
    "    r = 64, #64\n",
    "    lora_alpha = 16, #16\n",
    "    lora_dropout = 0.1 #0.1\n",
    ")\n",
    "#llm_model = get_peft_model(llm_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not DatasetDict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Start Training with dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m finetune_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# GO OVER\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformatting_func\u001b[39m(example):\n\u001b[0;32m      5\u001b[0m     output_texts \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Joshua\\Desktop\\python_ai\\.venv\\Lib\\site-packages\\datasets\\load.py:2588\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_files:\n\u001b[0;32m   2587\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_files\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. It should be either non-empty or None (default).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATASET_STATE_JSON_FILENAME\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m   2589\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2590\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to load a dataset that was saved using `save_to_disk`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2591\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `load_from_disk` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2592\u001b[0m     )\n\u001b[0;32m   2594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming \u001b[38;5;129;01mand\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:871\u001b[0m, in \u001b[0;36mPath.__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[1;32m--> 871\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:509\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m--> 509\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:493\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    491\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     a \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(a)\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[0;32m    496\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not DatasetDict"
     ]
    }
   ],
   "source": [
    "# Start Training with dataset\n",
    "finetune_dataset = load_dataset(path=dataset, split=\"train\") # GO OVER\n",
    "\n",
    "def formatting_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['input'])):\n",
    "        text = f\"### Input: {example['input'][i]}\\n ### Output: {example['output'][i]}\\n ### Instruction: {example['instruction'][i]}\\n ### Prompt: {example['prompt'][i]}\"\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "\n",
    "llm_model_trainer = SFTTrainer(\n",
    "    model=llm_model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=finetune_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config = peft_config,\n",
    "    formatting_func=formatting_func,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "latest_checkpoint = \"./test_trainer/checkpoint-1\"\n",
    "\n",
    "if latest_checkpoint:\n",
    "    print(f\"Resuming training from checkpoint: {latest_checkpoint}\")\n",
    "    llm_model_trainer.train(resume_from_checkpoint=latest_checkpoint)\n",
    "else:\n",
    "    print(\"Starting training from scratch\")\n",
    "    llm_model_trainer.train()\n",
    "\n",
    "# # Pipeline for taking in inputs\n",
    "# pipeline = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device=\"cuda\",\n",
    "# )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
